---
title: Proportional reasoning across formats
author:
  - name: Vidushi Kataria
    affil: 1
    email: vk412@scarletmail.rutgers.edu
affiliation:
  - num: 1
    address: Rutgers University, New Brunswick
output: 
  posterdown::posterdown_betterland:
    self_contained: false
    pandoc_args: --mathjax
    number_sections: false
---

```{r, include=FALSE}
knitr::opts_chunk$set(results = 'asis',
                      echo = FALSE,
                      warning = FALSE,
                      tidy = FALSE,
                      message = FALSE,
                      fig.align = 'center',
                      out.width = "100%")
options(knitr.table.format = "html") 

library(tidyverse)
library(ggdist)

probtask <- read_csv("data/MFIndD_probtask.csv")
```


# Introduction

Comparing proportions is sometimes very hard! But, even infants seem to be able to do it a little bit. The purpose of this science project was to better understand how well people compare proportions when they are presented in different formats. The purpose of this class assignment is to take the R-code and plots we've been generating over the last several weeks and put it all together into one poster format.

```{r, include=FALSE}
knitr::write_bib(c('posterdown', 'rmarkdown','pagedown'), 'packages.bib')
```

## Research Objectives

1. Does average performance vary across format type?
2. Does average performance vary across numerator congruency status?
3. Does numerator congruency vary across format type? (i.e., is there an interaction)

## Participants

```{r, num_participants, include=FALSE}
num_participants <- probtask %>%
  distinct(SubID)

count(num_participants)
```

A total of `r nrow(num_participants)` adults participated in the study. 

# Methods

First, participants were introduced to a story about a magic ball and that the outcome (i.e., blue or orange) depended on the proportions. They were then asked to compare the proportions of different images.

In other words, participants were shown two images of the same kind at the same time and were asked to decide which had a higher proportion of the shape (or dots) colored in blue.

`r knitr::include_graphics("images_WA10/Probtask_Trial.png")`

### Conditions 

There were four different conditions that changed what kinds of images the participants saw:

- divided blobs: blue and orange were entirely separate
- integrated blob: one blob, divided to be part blue and part orange
- separated dots: blue and orange dots were on opposite sides of the image
- integrated dots: blue and orange were intermixed 

`r knitr::include_graphics("images_WA10/Probtask_formats.png")`


# Results

1. Does average performance vary across format type, ignoring all other aspects of the stimuli?

```{r, include=FALSE}
accuracy_sum <- probtask %>%
  group_by(SubID, condition) %>%
  summarise(prop_corr = mean(correct, na.rm = TRUE)) %>%
  group_by(condition) %>%
  summarise(mean_prop_corr = mean(prop_corr, na.rm = TRUE))

accuracy_sum
```


```{r}
dist_plot <- accuracy_sum %>%
  ggplot(aes(x = condition, y = mean_prop_corr)) +
  stat_dotsinterval(aes(y = mean_prop_corr), 
                    color = "darkblue", # consistent color for interval points
                    slab_fill = "lightblue", # show soft contrast in slab,
                    dotsize = 0.6) + # adjusting dot size 
  labs(title = "Proportion Correct Responses w/ Distributional Info.",
       x = "Condition", y = "Mean Proportion Correct") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

dist_plot
```



When considering only format type (blobs vs. dots), this plot reveals no clear systematic difference in average performance between the two formats, as both blob and dot conditions show similar ranges of accuracy (approx 62-69% correct responses) w/ substantial overlap in their distributions.


2. How are reaction time and accuracy related?

```{r, include=FALSE}
summary_probtask <- probtask %>%
  group_by(SubID, condition) %>%
  summarise(
    rt = mean(rt, na.rm = TRUE),
    correct = mean(correct, na.rm = TRUE)) %>%
  ungroup()

head(summary_probtask)
```


```{r}
ggplot(summary_probtask, aes(x = rt, y = correct, color = condition)) +
  geom_point() +
  facet_wrap(~condition) +
  labs(
    title = "Reaction Time vs Accuracy by Condition",
    x = "Reaction Time (ms)", 
    y = "Proportion Correct") +
  theme_minimal()
```

According to this plot, reaction time tends to have an overall **positive** correlation. As reaction time *increases*, the proportion correct appears to *rise.* (However, there is some variability with *blob_stacked* and *dots_EqSizeSep*).


3. How does numerator congruency interact with format type?

```{r, include=FALSE, warning=FALSE}
prob_data_mod <- probtask %>%
  separate(left_stim, into = c("left_numerator", "left_other"), sep = "_",
           convert = TRUE) %>%
  separate(right_stim, into = c("right_numerator", "right_other"), sep = "_",
           convert = TRUE) %>%
  mutate(
    left_proportion_value = left_numerator / (left_numerator + left_other),
    right_proportion_value = right_numerator / (right_numerator + right_other)) %>%
  mutate(
    larger_numerator = case_when(left_numerator > right_numerator ~ "left",
                                 TRUE ~ "right")) %>%
  mutate(
    larger_proportion = case_when(
      left_proportion_value > right_proportion_value ~ "left",
      TRUE ~ "right")) %>%
  mutate(
    num_congruent = case_when(
      larger_numerator == larger_proportion ~ TRUE,
      TRUE ~ FALSE))
```


```{r, include=FALSE, warning=FALSE}
plot_data <- prob_data_mod %>%
  mutate(response = as.numeric(response)) %>%
  group_by(SubID, condition, num_congruent) %>%
  summarize(proportion_correct = mean(right_proportion_value + left_proportion_value, na.rm = TRUE), .groups = "drop")
```


```{r}
plot <- ggplot(plot_data, aes(x = condition, y = proportion_correct,
                      color = num_congruent)) +
  stat_halfeye() +
  labs(
    x = "Condition",
    y = "Proportion Correct",
    color = "Numerator Congruency") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

print(plot)
```

Across all four visualization conditions, participants consistently performed better when the numerator was congruent (TRUE) with the overall ratio compared to when it was incongruent (FALSE). 

# Interpretations

The three key findings from these three objectives are **format effect** (blobs vs. dots), **speed-accuracy relationship**, and the **numerator congruency effect**. 
The choice between blob or dots format does not appear to meaningfully impact performance accuracy.
There appears to be a speed-accuracy tradeoff, where participants who took more time tended to achieve a higher accuracy. However, there was some variation in the blob_stacked and dots_EqSizeSep formats. 
There was also a consistent pattern that emerged across all visualization types where performance was superior when the numerator aligned with the overall ratio. 

# Conclusions

1. Personally, the most annoying thing about this assignment (and making posters/presentations in R in general) is not knowing what is going to print before knitting. I think labeling code chunks can be a pain as well. But at least R tells you immediately after knitting what the issue is.

2. The most satisfying thing about this assignment is seeing everything you intend to print while knitting your poster. 




